{
 "cells": [
  {
   "source": [
    "# this notebook tries entity embeddings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48842, 15)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df = pd.read_csv(r'data/adult.csv')\n",
    "# df = pd.read_csv('adult.csv').sample(frac=0.3)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "n_estimators = 100\n",
    "max_samples = 0.5\n",
    "max_features = 0.5\n",
    "min_samples_leaf = 10\n",
    "\n",
    "# fastai nn\n",
    "bs = 1024 # batch size\n",
    "fc_1 = 250\n",
    "fc_2 = 100\n",
    "n_epochs = 10\n",
    "lr = 3e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train baseline rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total non-embedded feats: 108\naccuracy: 0.8641\nroc auc: 0.7814\n"
     ]
    }
   ],
   "source": [
    "# rf baseline with dummy variables\n",
    "# %%time\n",
    "\n",
    "x = df.drop('income', axis=1)\n",
    "x = pd.get_dummies(x)\n",
    "\n",
    "y = df['income']\n",
    "y = y.map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=1)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                            max_samples=max_samples,\n",
    "                            max_features=max_features,\n",
    "                            min_samples_leaf=min_samples_leaf).fit(x_train, y_train)\n",
    "                            \n",
    "preds = rf.predict(x_valid)\n",
    "\n",
    "roc_baseline = round(roc_auc_score(y_valid, preds), 4)\n",
    "\n",
    "print(f'total non-embedded feats: {len(x.columns)}')\n",
    "print(f'accuracy: {round(accuracy_score(y_valid, preds), 4)}')\n",
    "print(f'roc auc: {roc_baseline}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastai embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    }
   ],
   "source": [
    "# fastai nn with embeddings\n",
    "# %%time\n",
    "\n",
    "# prepare data for embeddings\n",
    "dep_var = 'income' # our target var\n",
    "\n",
    "num, cat = cont_cat_split(df, max_card=50, dep_var=dep_var) # numerical vs categorical split based on cardinality\n",
    "\n",
    "splits = RandomSplitter()(range_of(df)) # split data\n",
    "procs = [Categorify, Normalize, FillMissing] # needed augs\n",
    "\n",
    "to = TabularPandas(df, procs, cat, num, y_names=dep_var, splits=splits) # data block ~ torch dataset\n",
    "dls = to.dataloaders(bs, device=device) # loader\n",
    "\n",
    "learn = tabular_learner(dls, layers=[fc_1, fc_2], n_out=2) # model to embed our cat values. Can tune (nn) layers.\n",
    "learn.fit_one_cycle(n_epochs, lr) # train the model for some epochs\n",
    "\n",
    "# scores in fastai\n",
    "preds, _ = learn.get_preds()\n",
    "\n",
    "# acc_fast = round(accuracy_score(targs.flatten(), preds.argmax(1)), 4)\n",
    "acc_fast = round(accuracy_score(to.valid.y, preds.argmax(1)), 4)\n",
    "roc_fast = round(roc_auc_score(to.valid.y, preds.argmax(1)), 4)\n",
    "\n",
    "print(f'total all embeded feats: {len(num)+len(cat)}')\n",
    "print(f'accuracy: {acc_fast}')\n",
    "print(f'roc auc: {roc_fast}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "40442    0\n",
       "13156    0\n",
       "5917     0\n",
       "39622    1\n",
       "1345     1\n",
       "        ..\n",
       "28027    0\n",
       "24288    0\n",
       "34180    0\n",
       "19406    1\n",
       "11399    0\n",
       "Name: income, Length: 39074, dtype: int8"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "to.train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make it more readbale\n",
    "x_train = to.train.xs\n",
    "y_train = to.train.y\n",
    "\n",
    "x_valid = to.valid.xs\n",
    "y_valid = to.valid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to embed features\n",
    "def embed_features(learner, df):\n",
    "  \"\"\"\n",
    "  learner: fastai Learner used to train the neural net\n",
    "  df: DataFrame containing input variables. Categorical values are defined by their rank. \n",
    " ::return:: copy of `df` with embeddings replacing each categorical variable\n",
    "  \"\"\"\n",
    "  df = df.copy()\n",
    "  for i, col in enumerate(learn.dls.cat_names): # names of all cat cols\n",
    "    \n",
    "    # get matrix containing each row's embedding vector\n",
    "    emb = learn.model.embeds[i]\n",
    "    emb_data = emb(tensor(df[col], dtype=torch.int64))\n",
    "    emb_names = [f'{col}_{j}' for j in range(emb_data.shape[1])]\n",
    "    \n",
    "    # join the embedded category and drop the old feature column\n",
    "    feat_df = pd.DataFrame(data=emb_data, index=df.index, columns=emb_names)\n",
    "    df = df.drop(col, axis=1)\n",
    "    df = df.join(feat_df)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how df look before and after embeddings\n",
    "# df.sample(1)\n",
    "# df_train_emb.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train another rf with all the new embeded cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total all embeded feats: 604\naccuracy: 0.8317\nroc auc: 0.7727\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# embedded df\n",
    "x_train_emb = embed_features(learn, x_train)\n",
    "x_valid_emb = embed_features(learn, x_valid)\n",
    "\n",
    "# a lot of new features. Could take some time to cycle through all of them (~30-40 sec)\n",
    "rf_emb = RandomForestClassifier(n_estimators=20, # we will only need this model to find important features\n",
    "                                max_samples=max_samples,\n",
    "                                max_features=max_features,\n",
    "                                min_samples_leaf=min_samples_leaf).fit(x_train_emb, y_train)\n",
    "\n",
    "preds = rf_emb.predict(x_valid_emb)\n",
    "\n",
    "roc_emb = round(roc_auc_score(y_valid, preds), 4)\n",
    "\n",
    "print(f'total all embeded feats: {len(x_train_emb.columns)}')\n",
    "print(f'accuracy: {round(accuracy_score(y_valid, preds), 4)}')\n",
    "print(f'roc auc: {roc_emb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result is much worse. There could be too many features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's try to filter out most important features and build rf again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num of features not equal to 0: 580\n",
      "total filtered embeded feats: 580\n",
      "accuracy: 0.8307\n",
      "roc auc: 0.7726\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# using rf model trained with all the embeded features build df with importance values\n",
    "fi = pd.DataFrame({'cols': x_train_emb.columns, 'imp': rf_emb.feature_importances_}).sort_values(by='imp', ascending=False) \n",
    "\n",
    "imp_cols = fi[fi['imp'] != 0].cols.tolist() # filter important cols. We can try different threshold\n",
    "print(f'num of features not equal to 0: {len(imp_cols)}')\n",
    "\n",
    "x_train_emb_filt = x_train_emb[imp_cols] # df with important features\n",
    "x_valid_emb_filt = x_valid_emb[imp_cols]\n",
    "\n",
    "rf_emb_filt = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                     max_samples=max_samples,\n",
    "                                     max_features=max_features,\n",
    "                                     min_samples_leaf=min_samples_leaf).fit(x_train_emb_filt, y_train)\n",
    "\n",
    "# preds\n",
    "preds = rf_emb_filt.predict(x_valid_emb_filt)\n",
    "\n",
    "roc_emb_filt = round(roc_auc_score(y_valid, preds), 4)\n",
    "\n",
    "print(f'total filtered embeded feats: {len(x_train_emb_filt.columns)}')\n",
    "print(f'accuracy: {round(accuracy_score(y_valid, preds), 4)}')\n",
    "print(f'roc auc: {roc_emb_filt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc dummy: 0.7814\nroc fast: 0.7952\nroc emb: 0.7727\nroc emb filtered: 0.7726\n"
     ]
    }
   ],
   "source": [
    "print(f'roc dummy: {roc_baseline}')\n",
    "print(f'roc fast: {roc_fast}') \n",
    "print(f'roc emb: {roc_emb}')\n",
    "print(f'roc emb filtered: {roc_emb_filt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance plot\n",
    "# def plot_fi(fi):\n",
    "#     return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n",
    "\n",
    "# plot_fi(fi[:20]);"
   ]
  },
  {
   "source": [
    "# need to redo it to calculate score by adding more features every itteration\n",
    "# instead of increasing importance and do a lot of similar operations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # using rf model trained with all the embeded features build df with importance values\n",
    "# fi = pd.DataFrame({'cols': x_train_emb.columns, 'imp': rf_emb.feature_importances_}).sort_values(by='imp', ascending=False) \n",
    "\n",
    "# importance = []\n",
    "# roc_score = []\n",
    "\n",
    "# # when we cycle through importances in for loop later, and set max_imp too high, we will get an error because there wont be any features with importance that high. So we cant use linspace(0,1,20) for example because when we get to importance 0.2, for example, we wont have any features (all of them <0.1) and it will throw an error. That is why I find and set max importance from the df and deduct something from it to guarantee I have at least 1 feature when we reach that max importance\n",
    "# max_imp = fi.imp.max() - 1e-6\n",
    "\n",
    "# for i in np.linspace(0, max_imp, 40): # MAKE SURE YOU CHOOSE AT LEAST SOME FEATURES\n",
    "\n",
    "#     t0 = time.time()\n",
    "\n",
    "#     imp_cols = fi[fi['imp'] > i].cols.tolist() # filter important cols. We can try different threshold\n",
    "#     # print(f'for {i:.3f}: {imp_cols[:5]}\\n') # you can check the number of features returned here\n",
    "\n",
    "#     x_train_emb_filt = x_train_emb[imp_cols] # df with important features\n",
    "#     x_valid_emb_filt = x_valid_emb[imp_cols]\n",
    "\n",
    "#     # print(f'total features: {x_train_emb_filt.shape[1]}')\n",
    "\n",
    "#     rf_emb_filt = RandomForestClassifier(n_estimators=n_estimators,\n",
    "#                                          max_samples=max_samples, \n",
    "#                                          max_features=max_features,\n",
    "#                                          min_samples_leaf=min_samples_leaf).fit(x_train_emb_filt, y_train)\n",
    "\n",
    "#     # preds\n",
    "#     preds = rf_emb_filt.predict(x_valid_emb_filt)\n",
    "\n",
    "#     roc_emb_filt = round(roc_auc_score(y_valid, preds), 4)\n",
    "\n",
    "#     importance.append(i)\n",
    "#     roc_score.append(roc_emb_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.xlabel('importance')\n",
    "# plt.ylabel('roc auc score')\n",
    "# # plt.scatter(importance, roc_score);\n",
    "# print(f'best roc score: {np.max(roc_score)} is when imortantce threshold > {importance[np.argmax(roc_score)]:.4f}')\n",
    "# plt.plot(importance, roc_score, '-o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "bd47a18303be29f6974e8153b6e52f9a90ee51d979b528b256bf5f0592078974"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}